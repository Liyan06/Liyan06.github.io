<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Overlook of Relation Extraction | Liyan Tang</title>
<meta name="keywords" content="NLP, RE" />
<meta name="description" content="Information Extraction v.s. Relation Extraction Information Extraction: Information extraction is the task of automatically extracting structured information from unstructured and/or semi-structured machine-readable documents and other electronically represented sources.
Relation extraction (RE) is an important task in IE. It focuses on extracting relations between entities. A complete relation RE system consists of
 a named entity recognizer to identify named entities from text. an entity linker to link entities to existing knowledge graphs.">
<meta name="author" content="Theme PaperMod">
<link rel="canonical" href="https://Liyan06.github.io/posts/relation_extraction/" />
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.35cd0f65a15cafa92372b8313deef5960aae04b90ad722f2bbf509eb0468137e.css" integrity="sha256-Nc0PZaFcr6kjcrgxPe71lgquBLkK1yLyu/UJ6wRoE34=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js" integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5&#43;kdJvBz5iKbt6B5PJI="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://Liyan06.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://Liyan06.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://Liyan06.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://Liyan06.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://Liyan06.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.85.0" />
<script>
MathJax = {
  tex: {
    inlineMath: [ ['$', '$'], ['\\(', '\\)'] ]
  }
  ,svg: {
    fontCache: 'global'
  }
};
</script>
<script
  type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>
<meta property="og:title" content="Overlook of Relation Extraction" />
<meta property="og:description" content="Information Extraction v.s. Relation Extraction Information Extraction: Information extraction is the task of automatically extracting structured information from unstructured and/or semi-structured machine-readable documents and other electronically represented sources.
Relation extraction (RE) is an important task in IE. It focuses on extracting relations between entities. A complete relation RE system consists of
 a named entity recognizer to identify named entities from text. an entity linker to link entities to existing knowledge graphs." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://Liyan06.github.io/posts/relation_extraction/" /><meta property="og:image" content="https://Liyan06.github.io/papermod-cover.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-01-03T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2021-01-03T00:00:00&#43;00:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://Liyan06.github.io/papermod-cover.png"/>

<meta name="twitter:title" content="Overlook of Relation Extraction"/>
<meta name="twitter:description" content="Information Extraction v.s. Relation Extraction Information Extraction: Information extraction is the task of automatically extracting structured information from unstructured and/or semi-structured machine-readable documents and other electronically represented sources.
Relation extraction (RE) is an important task in IE. It focuses on extracting relations between entities. A complete relation RE system consists of
 a named entity recognizer to identify named entities from text. an entity linker to link entities to existing knowledge graphs."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://Liyan06.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Overlook of Relation Extraction",
      "item": "https://Liyan06.github.io/posts/relation_extraction/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Overlook of Relation Extraction",
  "name": "Overlook of Relation Extraction",
  "description": "Information Extraction v.s. Relation Extraction Information Extraction: Information extraction is the task of automatically extracting structured information from unstructured and/or semi-structured machine-readable documents and other electronically represented sources.\nRelation extraction (RE) is an important task in IE. It focuses on extracting relations between entities. A complete relation RE system consists of\n a named entity recognizer to identify named entities from text. an entity linker to link entities to existing knowledge graphs.",
  "keywords": [
    "NLP", "RE"
  ],
  "articleBody": "Information Extraction v.s. Relation Extraction Information Extraction: Information extraction is the task of automatically extracting structured information from unstructured and/or semi-structured machine-readable documents and other electronically represented sources.\nRelation extraction (RE) is an important task in IE. It focuses on extracting relations between entities. A complete relation RE system consists of\n a named entity recognizer to identify named entities from text. an entity linker to link entities to existing knowledge graphs. a relational classifier to determine relations between entities by given context (most difficult and important).  Existing Works of RE RE methods follows the typical supervised setting, from early pattern-based methods, statistical approaches, to recent neural models.\nPattern-based Methods The early methods use sentence analysis tools to identify syntactic elements in text, then automatically construct pattern rules from these elements. Later work involves larger corpora, more formats of patterns and more efficient ways of extraction.\nStatistical Relation Extraction Models Statistical Methods requires less human efforts so that statistical relation extraction (SRE) has been extensively studied. Approaches includes:\n feature-based methods which design lexical, syntactic and semantic features for entity pairs and their corresponding context (hard to design features). kernel-based methods measures the similarities between relation representations and textual instances (hard to design kernel functions). Graphical methods abstract the dependencies between entities, text and relations in the form of directed acyclic graphs, and then use inference models to identify the correct relations (still limited model capacities). embedding models. Encode text into low-dimensional semantic spaces and extract relations from textual embeddings. E.g. Knowledge Graph (KG) embeddings.  Neural Relation Extraction Methods The performance of SOTA RE models. The adoption of neural models began in 2013. Neural relation extraction (NRE) models can effectively capture textual information and generalize to wider range of data. NRE mainly utilizes both word embeddings and positional embeddings and focus on designing and utilizing various network architectures to capture the relational semantics within text. Methods includes:\n Recursive Neural Networks. Learn compositional representations for sentences recursively. Convolutional neural networks (CNNs). Model local textual patterns. Recurrent neural networks (RNNs). Handle long sequential data. Graph neural networks (GNNs). Build word/entity graphs for reasoning. Attention-based neural networks. Aggregate global relational information.  Currently, Transformers and Pre-trained LM models achieves SOTA on intra-sentence RE.\nFuture Directions Despite the success of existing RE methods, most of them still work in a simplified setting. These methods mainly focus on training models with large amounts of human annotations to classify two given entities within one sentence into pre-defined relations. However, the real world is much more complicated than this simple setting:\n collecting high-quality human annotations is expensive and time-consuming. many long-tail relations cannot provide large amounts of training examples. most facts are expressed by long context consisting of multiple sentences. using a pre-defined set to cover those relations with open-ended growth is difficult.  Utilizing More Data The researchers have formed a consensus that utilizing more data is a potential way towards more powerful RE models.\nDistant supervision (DS) assumption has been used to automatically label data by aligning existing KGs with plain text. For any entity pair in KGs, sentences mentioning both the entities will be labeled with their corresponding relations in KGs.\nHere is an illustration of DS relation extraction. With the fact (Apple Inc., product, iPhone), DS finds all sentences mentioning the two entities and annotates them with the relation product, which inevitably brings noise labels. Methods to Denoise DS Data  Adopt multi-instance learning by combining sentences with same entity pairs and then selecting informative instances from them. Incorporating extra context information such as KGs. Utilize sophisticated mechanisms and training strategies to enhance distantly supervised NRE models.  Open Problem for Utilizing More Data  Existing DS methods focus on denoising auto-labeled instances. Explore better DS schemes is valuable. Perform unsupervised or semi-supervised learning for utilizing large-scale unlabeled data as well as using knowledge from KGs and introducing human experts in the loop.  Performing More Efficient Learning Real-world relation distributions are long-tail and most relations have very limited relational facts and corresponding sentences. We can see the long tail distributions from two DS datasets in the following figure:\nFew-shot Learning Few-shot learning is a good fit for learning long-tail relations efficiently. It trains good representations of instances or learns ways of fast adaptation from existing large-scale data, and then transfer to new tasks.\nA typical few-shot learning setting is the N-way K-shot setting, where models are given N random-sampled new relations, along with K training examples for each relation. Here is an example. Give a few instances for new relation types, few-shot RE models classify query sentences into one of the given relations.\nHere are a few challenges for few-shot learning:\n Few-shot domain adaptation. Few-shot none-of-the-above detection. Conventional few-shot models have the difficulty to form a good representation for the none-of-the-above (NOTA) relation in the N-way K-shot setting. Therefore, it is crucial to study how to identify NOTA instances . Few-shot RE may result in a easy classification task if total amount of relations is small. As the following figure shows, as the number of relations increase, the performance drops. Current models cannot truly understand relations similar in semantics.   Handling More Complicated Context Most existing methods focus on intra-sentence RE and thus are inadequate for identifying relational facts expressed in a long document. Extracting relations from complicated context is a challenging task requiring reading, memorizing and reasoning for discovering relational facts across multiple sentences.\nHere is a post (Connecting the Dots: Document-level Neural Relation Extraction with Edge-oriented Graphs) I wrote for explaining using GNN on document-level relation extraction task.\nOrienting More Open Domains Our world undergoes growth of relations and it is not possible to pre-specify all relations by human experts. Thus, we need RE systems that do not rely on pre-defined relation schemas and can work in open scenarios. Here are current explorations in handling open relations:\n Open information extraction (Open IE), which extracts relation phrases and arguments (entities) from text.  Relation discovery, which discover unseen relation types from unsupervised data. Here is an example of casting relation discovery as a clustering task.   Note: There are many redundant extracted relations. Normalizing these phrases is crucial for downstream tasks. For example, relations on (Barack Obama, was born in , Honolulu) and (Obama, place of birth, Honolulu) are actually identical. So they should be normalized.\n Reference:\n More Data, More Relations, More Context and More Openness: A Review and Outlook for Relation Extraction. https://arxiv.org/pdf/2004.03186.pdf. Connecting the Dots: Document-level Neural Relation Extraction with Edge-oriented Graphs. https://arxiv.org/pdf/1909.00228.pdf. Distant supervision for relation extraction without labeled data. https://www.aclweb.org/anthology/P09-1113.pdf.  ",
  "wordCount" : "1082",
  "inLanguage": "en",
  "datePublished": "2021-01-03T00:00:00Z",
  "dateModified": "2021-01-03T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Theme PaperMod"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://Liyan06.github.io/posts/relation_extraction/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Liyan Tang",
    "logo": {
      "@type": "ImageObject",
      "url": "https://Liyan06.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>
<noscript>
    <style type="text/css">
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: #1d1e20;
                --entry: #2e2e33;
                --primary: rgba(255, 255, 255, 0.84);
                --secondary: rgba(255, 255, 255, 0.56);
                --tertiary: rgba(255, 255, 255, 0.16);
                --content: rgba(255, 255, 255, 0.74);
                --hljs-bg: #2e2e33;
                --code-bg: #37383e;
                --border: #333;
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://Liyan06.github.io/" accesskey="h" title="Liyan Tang (Alt + H)">Liyan Tang</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="https://Liyan06.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://Liyan06.github.io/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="https://Liyan06.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://Liyan06.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://Liyan06.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://Liyan06.github.io/posts/">Posts</a></div>
    <h1 class="post-title">
      Overlook of Relation Extraction
    </h1>
    <div class="post-meta">January 3, 2021&nbsp;·&nbsp;6 min&nbsp;·&nbsp;Theme PaperMod
</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <div class="details">Table of Contents</div>
        </summary>
        <div class="inner"><ul>
                <li>
                    <a href="#information-extraction-vs-relation-extraction" aria-label="Information Extraction v.s. Relation Extraction">Information Extraction v.s. Relation Extraction</a></li>
                <li>
                    <a href="#existing-works-of-re" aria-label="Existing Works of RE">Existing Works of RE</a><ul>
                        
                <li>
                    <a href="#pattern-based-methods" aria-label="Pattern-based Methods">Pattern-based Methods</a></li>
                <li>
                    <a href="#statistical-relation-extraction-models" aria-label="Statistical Relation Extraction Models">Statistical Relation Extraction Models</a></li>
                <li>
                    <a href="#neural-relation-extraction-methods" aria-label="Neural Relation Extraction Methods">Neural Relation Extraction Methods</a></li></ul>
                </li>
                <li>
                    <a href="#future-directions" aria-label="Future Directions">Future Directions</a><ul>
                        
                <li>
                    <a href="#utilizing-more-data" aria-label="Utilizing More Data">Utilizing More Data</a><ul>
                        
                <li>
                    <a href="#methods-to-denoise-ds-data" aria-label="Methods to Denoise DS Data">Methods to Denoise DS Data</a></li>
                <li>
                    <a href="#open-problem-for-utilizing-more-data" aria-label="Open Problem for Utilizing More Data">Open Problem for Utilizing More Data</a></li></ul>
                </li>
                <li>
                    <a href="#performing-more-efficient-learning" aria-label="Performing More Efficient Learning">Performing More Efficient Learning</a><ul>
                        
                <li>
                    <a href="#few-shot-learning" aria-label="Few-shot Learning">Few-shot Learning</a></li></ul>
                </li>
                <li>
                    <a href="#handling-more-complicated-context" aria-label="Handling More Complicated Context">Handling More Complicated Context</a></li>
                <li>
                    <a href="#orienting-more-open-domains" aria-label="Orienting More Open Domains">Orienting More Open Domains</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="information-extraction-vs-relation-extraction">Information Extraction v.s. Relation Extraction<a hidden class="anchor" aria-hidden="true" href="#information-extraction-vs-relation-extraction">#</a></h2>
<p><strong>Information Extraction:</strong> Information extraction is the task of automatically extracting structured information from unstructured and/or semi-structured machine-readable documents and other electronically represented sources.</p>
<p>Relation extraction (RE) is an important task in IE. It focuses on extracting relations between entities. A complete relation RE system consists of</p>
<ol>
<li>a named entity recognizer to identify named entities from text.</li>
<li>an entity linker to link entities to existing knowledge graphs.</li>
<li>a relational classifier to determine relations between entities by given context (most difficult and important).</li>
</ol>
<img src="https://img-blog.csdnimg.cn/20210103011251539.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0pheV9UYW5n,size_10,color_FFFFFF,t_70#pic_center" width=550>
<h2 id="existing-works-of-re">Existing Works of RE<a hidden class="anchor" aria-hidden="true" href="#existing-works-of-re">#</a></h2>
<p>RE methods follows the typical supervised setting, from early <strong>pattern-based methods, statistical approaches, to recent neural models.</strong></p>
<h3 id="pattern-based-methods">Pattern-based Methods<a hidden class="anchor" aria-hidden="true" href="#pattern-based-methods">#</a></h3>
<p>The early methods use sentence analysis tools to identify syntactic elements in text, then automatically construct pattern rules from these elements. Later work involves larger corpora, more formats of patterns and more efficient ways of extraction.</p>
<h3 id="statistical-relation-extraction-models">Statistical Relation Extraction Models<a hidden class="anchor" aria-hidden="true" href="#statistical-relation-extraction-models">#</a></h3>
<p>Statistical Methods requires less human efforts so that statistical relation extraction (SRE) has been extensively studied. Approaches includes:</p>
<ul>
<li><strong>feature-based methods</strong> which design lexical, syntactic and semantic features for entity pairs and their corresponding context (hard to design features).</li>
<li><strong>kernel-based methods</strong> measures the similarities between relation representations and textual instances (hard to design kernel functions).</li>
<li><strong>Graphical methods</strong> abstract the dependencies between entities, text and relations in the form of directed acyclic graphs, and then use inference models to identify the correct relations (still limited model capacities).</li>
<li><strong>embedding models</strong>. Encode text into low-dimensional semantic spaces and extract relations from textual embeddings. E.g. Knowledge Graph (KG) embeddings.</li>
</ul>
<h3 id="neural-relation-extraction-methods">Neural Relation Extraction Methods<a hidden class="anchor" aria-hidden="true" href="#neural-relation-extraction-methods">#</a></h3>
<p>The performance of SOTA RE models. The adoption of neural models began in 2013.
<img src="https://img-blog.csdnimg.cn/20210103010811185.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0pheV9UYW5n,size_10,color_FFFFFF,t_70#pic_center" width=550></p>
<p>Neural relation extraction (NRE) models can effectively capture textual information and generalize to wider range of data. NRE mainly utilizes both word embeddings and positional embeddings and focus on designing and utilizing various network architectures to capture the relational semantics within text. Methods includes:</p>
<ul>
<li>Recursive Neural Networks. Learn compositional representations for sentences recursively.</li>
<li>Convolutional neural networks (CNNs). Model local textual patterns.</li>
<li>Recurrent neural networks (RNNs). Handle long sequential data.</li>
<li>Graph neural networks (GNNs). Build word/entity graphs for reasoning.</li>
<li>Attention-based neural networks. Aggregate global relational information.</li>
</ul>
<p>Currently, Transformers and Pre-trained LM models achieves SOTA on <em>intra-sentence</em> RE.</p>
<h2 id="future-directions">Future Directions<a hidden class="anchor" aria-hidden="true" href="#future-directions">#</a></h2>
<p>Despite the success of existing RE methods, most of them still work in a simplified setting. These methods mainly focus on training models with large amounts of human annotations to classify two given entities within one sentence into pre-defined relations. However, the real world is much more complicated than this simple setting:</p>
<ul>
<li>collecting high-quality human annotations is expensive and time-consuming.</li>
<li>many long-tail relations cannot provide large amounts of training examples.</li>
<li>most facts are expressed by long context consisting of multiple sentences.</li>
<li>using a pre-defined set to cover those relations with open-ended growth is difficult.</li>
</ul>
<h3 id="utilizing-more-data">Utilizing More Data<a hidden class="anchor" aria-hidden="true" href="#utilizing-more-data">#</a></h3>
<p>The researchers have formed a consensus that utilizing more data is a potential way towards more powerful RE models.</p>
<p>Distant supervision (DS) assumption has been used to automatically label data by aligning existing KGs with plain text. For any entity pair in KGs, sentences mentioning both the entities will be labeled with their corresponding relations in KGs.</p>
<p>Here is an illustration of DS relation extraction. With the fact (<em>Apple Inc.</em>, <code>product</code>, <em>iPhone</em>), DS finds all sentences mentioning the two entities and annotates them with the relation <code>product</code>, <strong>which inevitably brings noise labels</strong>.
<img src="https://img-blog.csdnimg.cn/20210103012938136.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0pheV9UYW5n,size_10,color_FFFFFF,t_70#pic_center" width=550></p>
<h4 id="methods-to-denoise-ds-data">Methods to Denoise DS Data<a hidden class="anchor" aria-hidden="true" href="#methods-to-denoise-ds-data">#</a></h4>
<ul>
<li>Adopt multi-instance learning by combining sentences with same entity pairs and then selecting informative instances from them.</li>
<li>Incorporating extra context information such as KGs.</li>
<li>Utilize sophisticated mechanisms and training strategies to enhance distantly supervised NRE models.</li>
</ul>
<h4 id="open-problem-for-utilizing-more-data">Open Problem for Utilizing More Data<a hidden class="anchor" aria-hidden="true" href="#open-problem-for-utilizing-more-data">#</a></h4>
<ul>
<li>Existing DS methods focus on denoising auto-labeled instances. Explore better DS schemes is valuable.</li>
<li>Perform unsupervised or semi-supervised learning for utilizing large-scale unlabeled data as well as using knowledge from KGs and introducing human experts in the loop.</li>
</ul>
<h3 id="performing-more-efficient-learning">Performing More Efficient Learning<a hidden class="anchor" aria-hidden="true" href="#performing-more-efficient-learning">#</a></h3>
<p>Real-world relation distributions are long-tail and most relations have very limited relational facts and corresponding sentences. We can see the long tail distributions from two DS datasets in the following figure:</p>
<img src="https://img-blog.csdnimg.cn/2021010311282422.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0pheV9UYW5n,size_16,color_FFFFFF,t_70#pic_center" width=550>
<h4 id="few-shot-learning">Few-shot Learning<a hidden class="anchor" aria-hidden="true" href="#few-shot-learning">#</a></h4>
<p><strong>Few-shot learning</strong> is a good fit for learning long-tail relations efficiently.  It trains good representations of instances or learns ways of fast adaptation from existing large-scale data, and then transfer to new tasks.</p>
<p>A typical few-shot learning setting is the <strong>N-way K-shot</strong> setting, where models are given N random-sampled new relations, along with K training examples for each relation. Here is an example. Give a few instances for new relation types, few-shot RE models classify query sentences into one of the given relations.</p>
<img src="https://img-blog.csdnimg.cn/20210103113552226.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0pheV9UYW5n,size_10,color_FFFFFF,t_70#pic_center" width=550>
<p>Here are a few challenges for few-shot learning:</p>
<ul>
<li><strong>Few-shot domain adaptation</strong>.</li>
<li><strong>Few-shot none-of-the-above detection</strong>. Conventional few-shot models have the difficulty to form a good representation for the none-of-the-above (NOTA) relation in the N-way K-shot setting. Therefore, it is crucial to study how to identify NOTA instances .</li>
<li><strong>Few-shot RE may result in a easy classification task if total amount of relations is small</strong>. As the following figure shows, as the number of relations increase, the performance drops.</li>
<li><strong>Current models cannot truly understand relations similar in semantics</strong>.
<img src="https://img-blog.csdnimg.cn/20210103114721687.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0pheV9UYW5n,size_16,color_FFFFFF,t_70#pic_center" width=550></li>
</ul>
<h3 id="handling-more-complicated-context">Handling More Complicated Context<a hidden class="anchor" aria-hidden="true" href="#handling-more-complicated-context">#</a></h3>
<p>Most existing methods focus on intra-sentence RE and thus are inadequate for identifying relational facts expressed in a long document. Extracting relations from complicated context is a challenging task requiring reading, memorizing and reasoning for discovering relational facts across multiple sentences.</p>
<p>Here is a post (<a href="https://liyantang.blog.csdn.net/article/details/111948895">Connecting the Dots: Document-level Neural Relation Extraction with Edge-oriented Graphs</a>) I wrote for explaining using GNN on document-level relation extraction task.</p>
<h3 id="orienting-more-open-domains">Orienting More Open Domains<a hidden class="anchor" aria-hidden="true" href="#orienting-more-open-domains">#</a></h3>
<p>Our world undergoes growth of relations and it is not possible to pre-specify all relations by human experts. Thus, we need RE systems that do not rely on pre-defined relation schemas and can work in open scenarios. Here are current explorations in handling open relations:</p>
<ul>
<li><strong>Open information extraction (Open IE)</strong>, which extracts relation phrases and arguments (entities) from text.
<img src="https://img-blog.csdnimg.cn/20210103120825967.png#pic_center" width=550></li>
<li><strong>Relation discovery</strong>, which discover unseen relation types from unsupervised data. Here is an example of casting relation discovery as a clustering task.
<img src="https://img-blog.csdnimg.cn/20210103121202584.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0pheV9UYW5n,size_16,color_FFFFFF,t_70#pic_center" width=550></li>
</ul>
<p>Note: There are many redundant extracted relations. Normalizing these phrases is crucial for downstream tasks. For example, relations on (<em>Barack Obama</em>, <code>was born in</code> , <em>Honolulu</em>) and (<em>Obama</em>, <code>place of birth</code>, <em>Honolulu</em>) are actually identical. So they should be normalized.</p>
<hr>
<p>Reference:</p>
<ul>
<li>More Data, More Relations, More Context and More Openness: A Review and Outlook for Relation Extraction. <a href="https://arxiv.org/pdf/2004.03186.pdf">https://arxiv.org/pdf/2004.03186.pdf</a>.</li>
<li>Connecting the Dots: Document-level Neural Relation Extraction with Edge-oriented Graphs. <a href="https://arxiv.org/pdf/1909.00228.pdf">https://arxiv.org/pdf/1909.00228.pdf</a>.</li>
<li>Distant supervision for relation extraction without labeled data. <a href="https://www.aclweb.org/anthology/P09-1113.pdf">https://www.aclweb.org/anthology/P09-1113.pdf</a>.</li>
</ul>


  </div>
  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://Liyan06.github.io/tags/nlp/">NLP</a></li>
      <li><a href="https://Liyan06.github.io/tags/re/">RE</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://Liyan06.github.io/posts/decoupling_representation/">
    <span class="title">« Prev Page</span>
    <br>
    <span>Paper - Decoupling Representation and Classifier for Long-Tailed Recognition</span>
  </a>
  <a class="next" href="https://Liyan06.github.io/posts/connecting_the_dots/">
    <span class="title">Next Page »</span>
    <br>
    <span>Paper - Connecting the Dots: Document-level Neural Relation Extraction with Edge-oriented Graphs</span>
  </a>
</nav>

<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share Overlook of Relation Extraction on twitter"
        href="https://twitter.com/intent/tweet/?text=Overlook%20of%20Relation%20Extraction&amp;url=https%3a%2f%2fLiyan06.github.io%2fposts%2frelation_extraction%2f&amp;hashtags=NLP%2cRE">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Overlook of Relation Extraction on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fLiyan06.github.io%2fposts%2frelation_extraction%2f&amp;title=Overlook%20of%20Relation%20Extraction&amp;summary=Overlook%20of%20Relation%20Extraction&amp;source=https%3a%2f%2fLiyan06.github.io%2fposts%2frelation_extraction%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Overlook of Relation Extraction on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2fLiyan06.github.io%2fposts%2frelation_extraction%2f&title=Overlook%20of%20Relation%20Extraction">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Overlook of Relation Extraction on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fLiyan06.github.io%2fposts%2frelation_extraction%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Overlook of Relation Extraction on whatsapp"
        href="https://api.whatsapp.com/send?text=Overlook%20of%20Relation%20Extraction%20-%20https%3a%2f%2fLiyan06.github.io%2fposts%2frelation_extraction%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Overlook of Relation Extraction on telegram"
        href="https://telegram.me/share/url?text=Overlook%20of%20Relation%20Extraction&amp;url=https%3a%2f%2fLiyan06.github.io%2fposts%2frelation_extraction%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>

  </footer>
</article>
    </main>
    <footer class="footer">
    <span>&copy; 2021 <a href="https://Liyan06.github.io/">Liyan Tang</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)">
    <button class="top-link" id="top-link" type="button" accesskey="g">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z" />
        </svg>
    </button>
</a>

<script>
    let menu = document.getElementById('menu')
    menu.scrollLeft = localStorage.getItem("menu-scroll-position");
    menu.onscroll = function () {
        localStorage.setItem("menu-scroll-position", menu.scrollLeft);
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
