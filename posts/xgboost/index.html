<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>XGBoost | Liyan Tang</title>
<meta name="keywords" content="ML, MATH" />
<meta name="description" content="Bagging v.s. Boosting: Bagging: Leverages unstable base learners that are weak because of overfitting.
Boosting: Leverages stable base learners that are weak because of underfitting.
XGBoost Learning Process through XGBoost:
 How to set a objective function. Hard to solve directly, how to approximate. How to add tree structures into the objective function. Still hard to optimize, then have to use greedy algorithms.  Step 1. How to set an objective function Suppose we trained $K$ trees, then the prediction for the ith sample is $$\hat{y}i = \sum{k=1}^K f_k(x_i), f_k \in \mathcal{F}$$ where $K$ is the number of trees, $f$ is a function in the functional space $\mathcal{F}$, and $\mathcal{F}$ is the set of all possible CARTs.">
<meta name="author" content="Theme PaperMod">
<link rel="canonical" href="https://adityatelange.github.io/posts/xgboost/" />
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.35cd0f65a15cafa92372b8313deef5960aae04b90ad722f2bbf509eb0468137e.css" integrity="sha256-Nc0PZaFcr6kjcrgxPe71lgquBLkK1yLyu/UJ6wRoE34=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js" integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5&#43;kdJvBz5iKbt6B5PJI="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://adityatelange.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://adityatelange.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://adityatelange.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://adityatelange.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://adityatelange.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.85.0" />
<script>
MathJax = {
  tex: {
    inlineMath: [ ['$', '$'], ['\\(', '\\)'] ]
  }
  ,svg: {
    fontCache: 'global'
  }
};
</script>
<script
  type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>
<meta property="og:title" content="XGBoost" />
<meta property="og:description" content="Bagging v.s. Boosting: Bagging: Leverages unstable base learners that are weak because of overfitting.
Boosting: Leverages stable base learners that are weak because of underfitting.
XGBoost Learning Process through XGBoost:
 How to set a objective function. Hard to solve directly, how to approximate. How to add tree structures into the objective function. Still hard to optimize, then have to use greedy algorithms.  Step 1. How to set an objective function Suppose we trained $K$ trees, then the prediction for the ith sample is $$\hat{y}i = \sum{k=1}^K f_k(x_i), f_k \in \mathcal{F}$$ where $K$ is the number of trees, $f$ is a function in the functional space $\mathcal{F}$, and $\mathcal{F}$ is the set of all possible CARTs." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://adityatelange.github.io/posts/xgboost/" /><meta property="og:image" content="https://adityatelange.github.io/papermod-cover.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-03-27T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2020-03-27T00:00:00&#43;00:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://adityatelange.github.io/papermod-cover.png"/>

<meta name="twitter:title" content="XGBoost"/>
<meta name="twitter:description" content="Bagging v.s. Boosting: Bagging: Leverages unstable base learners that are weak because of overfitting.
Boosting: Leverages stable base learners that are weak because of underfitting.
XGBoost Learning Process through XGBoost:
 How to set a objective function. Hard to solve directly, how to approximate. How to add tree structures into the objective function. Still hard to optimize, then have to use greedy algorithms.  Step 1. How to set an objective function Suppose we trained $K$ trees, then the prediction for the ith sample is $$\hat{y}i = \sum{k=1}^K f_k(x_i), f_k \in \mathcal{F}$$ where $K$ is the number of trees, $f$ is a function in the functional space $\mathcal{F}$, and $\mathcal{F}$ is the set of all possible CARTs."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://adityatelange.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "XGBoost",
      "item": "https://adityatelange.github.io/posts/xgboost/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "XGBoost",
  "name": "XGBoost",
  "description": "Bagging v.s. Boosting: Bagging: Leverages unstable base learners that are weak because of overfitting.\nBoosting: Leverages stable base learners that are weak because of underfitting.\nXGBoost Learning Process through XGBoost:\n How to set a objective function. Hard to solve directly, how to approximate. How to add tree structures into the objective function. Still hard to optimize, then have to use greedy algorithms.  Step 1. How to set an objective function Suppose we trained $K$ trees, then the prediction for the ith sample is $$\\hat{y}i = \\sum{k=1}^K f_k(x_i), f_k \\in \\mathcal{F}$$ where $K$ is the number of trees, $f$ is a function in the functional space $\\mathcal{F}$, and $\\mathcal{F}$ is the set of all possible CARTs.",
  "keywords": [
    "ML", "MATH"
  ],
  "articleBody": "Bagging v.s. Boosting: Bagging: Leverages unstable base learners that are weak because of overfitting.\nBoosting: Leverages stable base learners that are weak because of underfitting.\nXGBoost Learning Process through XGBoost:\n How to set a objective function. Hard to solve directly, how to approximate. How to add tree structures into the objective function. Still hard to optimize, then have to use greedy algorithms.  Step 1. How to set an objective function Suppose we trained $K$ trees, then the prediction for the ith sample is $$\\hat{y}i = \\sum{k=1}^K f_k(x_i), f_k \\in \\mathcal{F}$$ where $K$ is the number of trees, $f$ is a function in the functional space $\\mathcal{F}$, and $\\mathcal{F}$ is the set of all possible CARTs.\nThe objective function to be optimized is given by $$\\text{obj} = \\sum_i^n l(y_i, \\hat{y}i) + \\sum{k=1}^K \\Omega(f_k)$$ The first term is the loss function and the second term controls trees' complexity. We see the undefined terms in this objective function are the loss function $l$ and model complexity $\\Omega (f_i)$. Functions $f_i$ are what we need to learn, each containing the structure of the tree and the leaf scores.\nwe use an additive strategy to build the model. That is, fix what we have learned, and add one new tree at a time. This is called Additive Training.\nNote that given $x_i$, the prediction $\\hat{y}_i^{(K)} = \\hat{y}_i^{(K-1)} + f_K(x_i)$, where the term $\\hat{y}_i^{(K-1)}$ is known and only $f_K(x_i)$ is unknown.\nNow, we can rewrite the objective function as Step 2. Hard to solve directly, how to approximate If the loss function is the MSE, then the objective function has a nice form. But for a general loss function, it is hard to optimize directly. Therefore, we need to approximate it. Here, we use second order Taylor approximation\nSo we can re-write the objective function as If we define constant term $g_i$, $h_i$ as $$g_i = \\partial_{\\hat{y}_i^{(K-1)}} l(y_i, \\hat{y}_i^{(K-1)}) \\\nf_i = \\partial_{\\hat{y}_i^{(K-1)}}^2 l(y_i, \\hat{y}_i^{(K-1)})$$ Also, since previous $K-1$ trees are fixed, we have $\\sum_{i=1}^n l(y_i, \\hat{y}_i^{(K-1)})$ fixed. Then we can write the objective function as\nNow, all previous trees' information is stored in terms $g_i$ and $h_i$. That‚Äôs how the $K$th tree is related to previous trees. Our new objective function now is $$ \\text{obj}K = \\sum{i=1}^n [g_if_K(x_i) + \\frac{1}{2}h_if_K^2(x_i)] + \\Omega(f_K)$$ The unknown at this point are $f_K$ and $\\Omega(f_K)$.\nStep 3. How to add tree structures into the objective function Redefine a tree:\n Define $I_j = {i|q(x_i)=j}$ to be the set of indices of data points assigned to the ùëó-th leaf. $T$ is the number of leaves. $q(x_i)$ is which leaf the $i$-th sample is assigned to. Term $q(x)$ defines the tree structure. $w_{q(x_i)}$ is the score of the assigned leaf. In XGBoost, we define the complexity as $\\Omega(f) = \\gamma T + \\frac{1}{2}\\lambda \\sum_{j=1}^T w_j^2$  Now the revised objective function is\nDefine $G_j = \\sum_{i\\in I_j} g_i$ and $H_j = \\sum_{i\\in I_j} h_i$ constants. The the objective function is $$\\text{obj}_{K} = \\sum^T_{j=1} [G_jw_j + \\frac{1}{2} (H_j+\\lambda) w_j^2] +\\gamma T$$\nRight now, the only unknown is $w_j$, which is independent respect to other terms. Take the derivative and set it to zero, we have $$w_j = -\\frac{G_j}{H_j+\\lambda}$$ Then the objective function achieve its minimum at $$ \\text{obj}K = -\\frac{1}{2} \\sum{j=1}^T \\frac{G_j^2}{H_j+\\lambda} + \\gamma T$$\nStep 4. Still hard to optimize, then have to use greedy algorithms For any tree structure, we are now able to find the minimum value of the objective function. Ideally we would brute force all possible tree structures and pick the one with the minimum objective function. However, this is impossible in practice and we use greedy algorithm instead. When we build decision trees, we use entropy to calculate the information gain. Now we are still going to use information gain, but the formula changes to\nwhere $L$ is the left leaf and $R$ is the right leaf.\n Reference:\n https://xgboost.readthedocs.io/en/latest/tutorials/model.html  ",
  "wordCount" : "641",
  "inLanguage": "en",
  "datePublished": "2020-03-27T00:00:00Z",
  "dateModified": "2020-03-27T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Theme PaperMod"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://adityatelange.github.io/posts/xgboost/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Liyan Tang",
    "logo": {
      "@type": "ImageObject",
      "url": "https://adityatelange.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>
<noscript>
    <style type="text/css">
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: #1d1e20;
                --entry: #2e2e33;
                --primary: rgba(255, 255, 255, 0.84);
                --secondary: rgba(255, 255, 255, 0.56);
                --tertiary: rgba(255, 255, 255, 0.16);
                --content: rgba(255, 255, 255, 0.74);
                --hljs-bg: #2e2e33;
                --code-bg: #37383e;
                --border: #333;
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://adityatelange.github.io/" accesskey="h" title="Liyan Tang (Alt + H)">Liyan Tang</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="https://adityatelange.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://adityatelange.github.io/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="https://adityatelange.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://adityatelange.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://adityatelange.github.io/">Home</a>&nbsp;¬ª&nbsp;<a href="https://adityatelange.github.io/posts/">Posts</a></div>
    <h1 class="post-title">
      XGBoost
    </h1>
    <div class="post-meta">March 27, 2020&nbsp;¬∑&nbsp;4 min&nbsp;¬∑&nbsp;Theme PaperMod
</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <div class="details">Table of Contents</div>
        </summary>
        <div class="inner"><ul>
                <li>
                    <a href="#bagging-vs-boosting" aria-label="Bagging v.s. Boosting:">Bagging v.s. Boosting:</a></li>
                <li>
                    <a href="#xgboost" aria-label="XGBoost">XGBoost</a><ul>
                        
                <li>
                    <a href="#step-1-how-to-set-an-objective-function" aria-label="Step 1. How to set an objective function">Step 1. How to set an objective function</a></li>
                <li>
                    <a href="#step-2-hard-to-solve-directly-how-to-approximate" aria-label="Step 2. Hard to solve directly, how to approximate">Step 2. Hard to solve directly, how to approximate</a></li>
                <li>
                    <a href="#step-3-how-to-add-tree-structures-into-the-objective-function" aria-label="Step 3. How to add tree structures into the objective function">Step 3. How to add tree structures into the objective function</a></li>
                <li>
                    <a href="#step-4-still-hard-to-optimize-then-have-to-use-greedy-algorithms" aria-label="Step 4. Still hard to optimize, then have to use greedy algorithms">Step 4. Still hard to optimize, then have to use greedy algorithms</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="bagging-vs-boosting">Bagging v.s. Boosting:<a hidden class="anchor" aria-hidden="true" href="#bagging-vs-boosting">#</a></h2>
<p>Bagging:
Leverages unstable base learners that are weak because of <em>overfitting</em>.</p>
<p>Boosting:
Leverages stable base learners that are weak because of <em>underfitting</em>.</p>
<h2 id="xgboost">XGBoost<a hidden class="anchor" aria-hidden="true" href="#xgboost">#</a></h2>
<p><em>Learning Process through XGBoost:</em></p>
<ol>
<li>How to set a objective function.</li>
<li>Hard to solve directly, how to approximate.</li>
<li>How to add tree structures into the objective function.</li>
<li>Still hard to optimize, then have to use greedy algorithms.</li>
</ol>
<h3 id="step-1-how-to-set-an-objective-function">Step 1. How to set an objective function<a hidden class="anchor" aria-hidden="true" href="#step-1-how-to-set-an-objective-function">#</a></h3>
<p>Suppose we trained $K$ trees, then the prediction for the <em>i</em>th sample is
$$\hat{y}<em>i = \sum</em>{k=1}^K f_k(x_i), f_k \in \mathcal{F}$$
where $K$ is the number of trees, $f$ is a function in the functional space $\mathcal{F}$, and $\mathcal{F}$ is the set of all possible CARTs.</p>
<p>The objective function to be optimized is given by
$$\text{obj} = \sum_i^n l(y_i, \hat{y}<em>i) + \sum</em>{k=1}^K \Omega(f_k)$$
The first term is the loss function and the second term controls trees' complexity. We see the undefined terms in this objective function are the loss function $l$ and model complexity $\Omega (f_i)$. Functions $f_i$ are what we need to learn, each containing the structure of the tree and the leaf scores.</p>
<p>we use an additive strategy to build the model. That is, fix what we have learned, and add one new tree at a time. This is called Additive Training.</p>
<img src="https://img-blog.csdnimg.cn/20200327133100615.png" width=500>
<p>Note that given $x_i$, the prediction $\hat{y}_i^{(K)} = \hat{y}_i^{(K-1)} + f_K(x_i)$, where the term $\hat{y}_i^{(K-1)}$ is known and only $f_K(x_i)$ is unknown.</p>
<p>Now, we can rewrite the objective function as
<img src="https://img-blog.csdnimg.cn/20200327141838440.png" width=500></p>
<h3 id="step-2-hard-to-solve-directly-how-to-approximate">Step 2. Hard to solve directly, how to approximate<a hidden class="anchor" aria-hidden="true" href="#step-2-hard-to-solve-directly-how-to-approximate">#</a></h3>
<p>If the loss function is the MSE, then the objective function has a nice form. But for a general loss function, it is hard to optimize directly. Therefore, we need to approximate it. Here, we use second order Taylor approximation</p>
<img src="https://img-blog.csdnimg.cn/20200327133731502.png" width=500>
<p>So we can re-write the objective function as
<img src="https://img-blog.csdnimg.cn/20200327133146571.png" width=700></p>
<p>If we define constant term $g_i$, $h_i$ as
$$g_i = \partial_{\hat{y}_i^{(K-1)}} l(y_i, \hat{y}_i^{(K-1)}) \<br>
f_i = \partial_{\hat{y}_i^{(K-1)}}^2 l(y_i, \hat{y}_i^{(K-1)})$$
Also, since previous $K-1$ trees are fixed, we have $\sum_{i=1}^n l(y_i, \hat{y}_i^{(K-1)})$ fixed. Then we can write the objective function as</p>
<img src="https://img-blog.csdnimg.cn/20200327134218676.png" width=500>
<p>Now, all previous trees' information is stored in terms $g_i$ and $h_i$. That&rsquo;s how the $K$th tree is related to previous trees. Our new objective function now is
$$ \text{obj}<em>K = \sum</em>{i=1}^n [g_if_K(x_i) + \frac{1}{2}h_if_K^2(x_i)] + \Omega(f_K)$$
The unknown at this point are $f_K$ and $\Omega(f_K)$.</p>
<h3 id="step-3-how-to-add-tree-structures-into-the-objective-function">Step 3. How to add tree structures into the objective function<a hidden class="anchor" aria-hidden="true" href="#step-3-how-to-add-tree-structures-into-the-objective-function">#</a></h3>
<p><em>Redefine a tree</em>:</p>
<ul>
<li>Define $I_j = {i|q(x_i)=j}$ to be the set of indices of data points assigned to the ùëó-th leaf.</li>
<li>$T$ is the number of leaves.</li>
<li>$q(x_i)$ is which leaf the $i$-th sample is assigned to. <strong>Term $q(x)$ defines the tree structure.</strong></li>
<li>$w_{q(x_i)}$ is the score of the assigned leaf.</li>
<li>In XGBoost, we define the complexity as $\Omega(f) = \gamma T + \frac{1}{2}\lambda \sum_{j=1}^T w_j^2$</li>
</ul>
<p>Now the revised objective function is</p>
<img src="https://img-blog.csdnimg.cn/20200327134545295.png" width=500>
<p>Define $G_j = \sum_{i\in I_j} g_i$ and $H_j = \sum_{i\in I_j} h_i$ constants. The the objective function is
$$\text{obj}_{K} = \sum^T_{j=1} [G_jw_j + \frac{1}{2} (H_j+\lambda) w_j^2] +\gamma T$$</p>
<p>Right now, the only unknown is $w_j$, which is independent respect to other terms. Take the derivative and set it to zero, we have
$$w_j = -\frac{G_j}{H_j+\lambda}$$
Then the objective function achieve its minimum at
$$ \text{obj}<em>K = -\frac{1}{2} \sum</em>{j=1}^T \frac{G_j^2}{H_j+\lambda} + \gamma T$$</p>
<h3 id="step-4-still-hard-to-optimize-then-have-to-use-greedy-algorithms">Step 4. Still hard to optimize, then have to use greedy algorithms<a hidden class="anchor" aria-hidden="true" href="#step-4-still-hard-to-optimize-then-have-to-use-greedy-algorithms">#</a></h3>
<p>For any tree structure, we are now able to find the minimum value of the objective function. Ideally we would brute force all possible tree structures and pick the one with the minimum objective function. However, this is impossible in practice and we use greedy algorithm instead. When we build decision trees, we use entropy to calculate the information gain. Now we are still going to use information gain, but the formula changes to</p>
<img src="https://img-blog.csdnimg.cn/20200327134327322.png" width=500>
<p>where $L$ is the left leaf and $R$ is the right leaf.</p>
<hr>
<p>Reference:</p>
<ul>
<li><a href="https://xgboost.readthedocs.io/en/latest/tutorials/model.html">https://xgboost.readthedocs.io/en/latest/tutorials/model.html</a></li>
</ul>


  </div>
  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://adityatelange.github.io/tags/ml/">ML</a></li>
      <li><a href="https://adityatelange.github.io/tags/math/">MATH</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://adityatelange.github.io/posts/convex1/">
    <span class="title">¬´ Prev Page</span>
    <br>
    <span>Introduction to Convex Optimization - Basic Concepts</span>
  </a>
  <a class="next" href="https://adityatelange.github.io/posts/mle/">
    <span class="title">Next Page ¬ª</span>
    <br>
    <span>Maximum Likelihood Estimation (MLE) and Maximum a Posteriori (MAP)</span>
  </a>
</nav>

<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share XGBoost on twitter"
        href="https://twitter.com/intent/tweet/?text=XGBoost&amp;url=https%3a%2f%2fadityatelange.github.io%2fposts%2fxgboost%2f&amp;hashtags=ML%2cMATH">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share XGBoost on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fadityatelange.github.io%2fposts%2fxgboost%2f&amp;title=XGBoost&amp;summary=XGBoost&amp;source=https%3a%2f%2fadityatelange.github.io%2fposts%2fxgboost%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share XGBoost on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2fadityatelange.github.io%2fposts%2fxgboost%2f&title=XGBoost">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share XGBoost on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fadityatelange.github.io%2fposts%2fxgboost%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share XGBoost on whatsapp"
        href="https://api.whatsapp.com/send?text=XGBoost%20-%20https%3a%2f%2fadityatelange.github.io%2fposts%2fxgboost%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share XGBoost on telegram"
        href="https://telegram.me/share/url?text=XGBoost&amp;url=https%3a%2f%2fadityatelange.github.io%2fposts%2fxgboost%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>

  </footer>
</article>
    </main>
    <footer class="footer">
    <span>&copy; 2021 <a href="https://adityatelange.github.io/">Liyan Tang</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)">
    <button class="top-link" id="top-link" type="button" accesskey="g">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z" />
        </svg>
    </button>
</a>

<script>
    let menu = document.getElementById('menu')
    menu.scrollLeft = localStorage.getItem("menu-scroll-position");
    menu.onscroll = function () {
        localStorage.setItem("menu-scroll-position", menu.scrollLeft);
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
